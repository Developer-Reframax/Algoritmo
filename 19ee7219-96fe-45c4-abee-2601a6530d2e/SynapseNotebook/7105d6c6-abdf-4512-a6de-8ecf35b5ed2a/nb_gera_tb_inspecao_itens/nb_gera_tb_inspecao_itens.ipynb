{"cells":[{"cell_type":"code","source":["# ==========================\n","# Importações\n","# ==========================\n","# %pip install requests  # (ative se necessário no Fabric)\n","import time\n","import requests\n","from typing import List, Dict\n","\n","from pyspark.sql import Row\n","from pyspark.sql import types as T\n","\n","# ==========================\n","# 1) Parâmetros\n","# ==========================\n","SUPABASE_TABLE = \"tb_inspecao_itens\"\n","SUPABASE_URL = f\"https://jewtbymqxxubjpwnjtux.supabase.co/rest/v1/{SUPABASE_TABLE}\"\n","\n","# Mesmas chaves (em produção, use Key Vault / credenciais do Fabric)\n","API_KEY = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impld3RieW1xeHh1Ympwd25qdHV4Iiwicm9sZSI6ImFub24iLCJpYXQiOjE3MTU3NzQ1ODQsImV4cCI6MjAzMTM1MDU4NH0.bs8NXsld5F98WdGTqt_9U0d1HY3DSXT4us0Ur1Rs8HE\"\n","BEARER_TOKEN = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Impld3RieW1xeHh1Ympwd25qdHV4Iiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTcxNTc3NDU4NCwiZXhwIjoyMDMxMzUwNTg0fQ.qJW13vrpLiF_uIHpGxNCy0iGpr--WhUK8g-AfeS4xm8\"\n","\n","# Lakehouse destino (ajuste para o seu workspace/lakehouse)\n","path_destino = \"abfss://ws_sistemas@onelake.dfs.fabric.microsoft.com/lk_systemmax.Lakehouse/Tables/tb_inspecao_itens\"\n","\n","# (Opcional) tabela gerenciada (catálogo). Deixe vazio para usar apenas o path físico.\n","tabela_destino = \"\"  # ex.: \"bronze.tb_inspecao_itens\"\n","\n","# Coleta\n","PAGE_SIZE = 1000\n","HTTP_TIMEOUT = 60  # s\n","\n","# ==========================\n","# 2) Schema explícito (todos string)\n","# ==========================\n","schema = T.StructType([\n","    T.StructField(\"id\", T.StringType(), True),\n","    T.StructField(\"created_at\", T.StringType(), True),\n","    T.StructField(\"idcadastro\", T.StringType(), True),\n","    T.StructField(\"item\", T.StringType(), True),\n","    T.StructField(\"posicao\", T.StringType(), True),\n","    T.StructField(\"opcao_na\", T.StringType(), True),\n","])\n","cols = [f.name for f in schema]\n","\n","# ==========================\n","# 3) Função GET com retry/backoff\n","# ==========================\n","def http_get_with_retry(url: str, headers: Dict[str, str], timeout: int, max_retries: int = 5) -> requests.Response:\n","    backoff = 1.5\n","    attempt = 0\n","    while True:\n","        try:\n","            resp = requests.get(url, headers=headers, timeout=timeout)\n","            if resp.status_code in (429, 500, 502, 503, 504):\n","                attempt += 1\n","                if attempt > max_retries:\n","                    resp.raise_for_status()\n","                time.sleep(backoff ** attempt)\n","                continue\n","            resp.raise_for_status()\n","            return resp\n","        except requests.RequestException:\n","            attempt += 1\n","            if attempt > max_retries:\n","                raise\n","            time.sleep(backoff ** attempt)\n","\n","# ==========================\n","# 4) Coleta paginada no Supabase\n","# ==========================\n","base_headers = {\n","    \"apikey\": API_KEY,\n","    \"Authorization\": f\"Bearer {BEARER_TOKEN}\",\n","    \"Accept\": \"application/json\",\n","}\n","\n","offset = 0\n","registros: List[Dict] = []\n","\n","while True:\n","    headers = {**base_headers, \"Range\": f\"{offset}-{offset + PAGE_SIZE - 1}\"}\n","    resp = http_get_with_retry(SUPABASE_URL, headers, timeout=HTTP_TIMEOUT)\n","    batch = resp.json()\n","    if not batch:\n","        break\n","    registros.extend(batch)\n","    if len(batch) < PAGE_SIZE:\n","        break\n","    offset += PAGE_SIZE\n","\n","print(f\"Registros coletados do Supabase ({SUPABASE_TABLE}): {len(registros)}\")\n","\n","# ==========================\n","# 5) Monta DataFrame sem inferência de tipos\n","# ==========================\n","if len(registros) == 0:\n","    df = spark.createDataFrame([], schema)\n","else:\n","    rows = []\n","    for rec in registros:\n","        fixed = {c: (None if rec.get(c) is None else str(rec.get(c))) for c in cols}\n","        rows.append(Row(**fixed))\n","    df = spark.createDataFrame(rows, schema)\n","\n","df.printSchema()\n","df.show(10, truncate=False)\n","\n","# ==========================\n","# 6) Escrita em Delta\n","# ==========================\n","if tabela_destino.strip():\n","    spark.sql(f\"DROP TABLE IF EXISTS {tabela_destino}\")\n","    df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(tabela_destino)\n","    print(f\"Tabela gerenciada gravada: {tabela_destino}\")\n","else:\n","    df.write.format(\"delta\").mode(\"overwrite\").save(path_destino)\n","    print(f\"Delta gravado no caminho: {path_destino}\")\n","\n","print(f\"Linhas salvas: {df.count()}\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"beab4929-90f2-435f-b706-b2833329f38d","normalized_state":"finished","queued_time":"2025-10-07T13:42:29.4384673Z","session_start_time":"2025-10-07T13:42:29.4394964Z","execution_start_time":"2025-10-07T13:42:42.8756952Z","execution_finish_time":"2025-10-07T13:42:52.4008294Z","parent_msg_id":"d0fcc428-91fb-46e6-abd9-eb7cc4ed9493"},"text/plain":"StatementMeta(, beab4929-90f2-435f-b706-b2833329f38d, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Registros coletados do Supabase (tb_inspecao_itens): 216\nroot\n |-- id: string (nullable = true)\n |-- created_at: string (nullable = true)\n |-- idcadastro: string (nullable = true)\n |-- item: string (nullable = true)\n |-- posicao: string (nullable = true)\n |-- opcao_na: string (nullable = true)\n\n+---+--------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+--------+\n|id |created_at                      |idcadastro|item                                                                                                                                                              |posicao|opcao_na|\n+---+--------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+--------+\n|601|2025-09-05T14:03:30.264043+00:00|97        |A CAPACIDADE DEFINIDA DE PESSOAS/CARGA INDICADA NA ETIQUETA DE LIBERAÇÃO ESTÁ SENDO RESPEITADA?                                                                   |NULL   |False   |\n|614|2025-09-05T14:37:25.808659+00:00|100       |OS DISPOSITIVOS DE PROTEÇÃO PARA USO DAS FERRAMENTAS (EPI,EPC) FORAM DEFINIDOS NO PROCEDIMENTO, ANALISE RISCO OU PTR, FORAM IMPLEMENTADOS E ESTÃO SENDO CUMPRIDOS?|NULL   |False   |\n|631|2025-09-05T14:53:27.636723+00:00|101       |NO CASO DE ESPAÇO CONFINADO COM RISCO DE EXPLOSÃO/INCÊNDIO, TODOS AS MEDIDAS DE CONTROLE E/OU MINIMIZAÇÃO FORAM DETERMINADAS E ADOTADAS?                          |NULL   |False   |\n|644|2025-09-05T15:09:01.630848+00:00|102       |O EQUIPAMENTO POSSUI ETIQUETA DE SINALIZAÇÃO DE BLOQUEIO DEVIDAMENTE PREENCHIDA?                                                                                  |NULL   |False   |\n|658|2025-09-05T16:37:10.602116+00:00|105       |O LOCAL ESCOLHIDO PARA O DDS FOI ADEQUADO? (ESPAÇO SUFICIENTE, VENTILAÇÃO, CONFORTO)                                                                              |NULL   |False   |\n|672|2025-09-05T16:43:59.109081+00:00|106       |OS COLABORADORES ESTÃO POSICIONADOS DE FORMA SEGURA, EM CONDIÇÕES QUE NÃO OFERECEM RISCOS DE QUEDA EM ALTURA OU MESMO NÍVEL?                                      |NULL   |False   |\n|684|2025-09-05T16:48:43.140285+00:00|106       |OS COLABORADORES ESTÃO ADOTANDO TODOS OS EPC PREVISTOS                                                                                                            |NULL   |False   |\n|697|2025-09-05T16:58:24.317743+00:00|107       |AS ÁREAS ESTÃO SEGURAS LIVRES DE VAZAMENTOS DE GASES TÓXICOS E TODOS OS COLABORADORES ESTÃO PORTANDO DETECTOR DE GASES DEVIDAMENTE CALIBRADO?                     |NULL   |False   |\n|568|2025-09-05T13:56:01.012496+00:00|97        |EMPREGADO POSSUI CRACHÁ DE INDENTIFICAÇÃO CONSIDERANDO: VALIDADE DO ASO E TREINAMENTOS PARA TRABALHO EM ALTURA?                                                   |NULL   |False   |\n|602|2025-09-05T14:03:44.63771+00:00 |97        |OS DISPOSITIVOS DE ANCORAGEM ESTÃO ADEQUADOS PARA A ATIVIDADE?                                                                                                    |NULL   |False   |\n+---+--------------------------------+----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------+-------+--------+\nonly showing top 10 rows\n\nDelta gravado no caminho: abfss://ws_sistemas@onelake.dfs.fabric.microsoft.com/lk_systemmax.Lakehouse/Tables/tb_inspecao_itens\nLinhas salvas: 216\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"cellStatus":"{\"Suporte BI\":{\"session_start_time\":\"2025-10-07T13:42:29.4394964Z\",\"execution_start_time\":\"2025-10-07T13:42:42.8756952Z\",\"execution_finish_time\":\"2025-10-07T13:42:52.4008294Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}"},"id":"79410c5f-a0fc-4ff1-bd78-4970963710fc"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}