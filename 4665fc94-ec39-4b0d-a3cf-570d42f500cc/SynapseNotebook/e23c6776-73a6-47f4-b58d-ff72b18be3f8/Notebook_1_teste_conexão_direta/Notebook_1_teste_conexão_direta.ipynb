{"cells":[{"cell_type":"code","source":["# ============================================\n","# 1) Parâmetros de conexão SQL Server (RM)\n","# ============================================\n","jdbc_hostname = \"142.0.64.50\"\n","jdbc_port = 38000\n","jdbc_database = \"C8VSAQ_144754_RM_PD\"\n","\n","jdbc_username = \"CLT144754LEITURA\"\n","jdbc_password = \"vnolx18963NLADF?@\"   # Ideal: usar credencial/Key Vault\n","\n","# JDBC CORRIGIDO -> porta com \":\" (não usar vírgula)\n","jdbc_url = (\n","    f\"jdbc:sqlserver://{jdbc_hostname}:{jdbc_port};\"\n","    f\"database={jdbc_database};\"\n","    \"encrypt=false;\"\n","    \"trustServerCertificate=true;\"\n",")\n","\n","print(\"JDBC URL:\", jdbc_url)\n","\n","# Caminho físico do lakehouse de destino\n","path_destino = \"abfss://ws_departamento_pessoal@onelake.dfs.fabric.microsoft.com/lk_ponto.Lakehouse/Tables/tab_gold_fato_obra_ponto\"\n","\n","\n","# ============================================\n","# 2) Consulta T-SQL (sua query completa)\n","# ============================================\n","consulta = \"\"\"\n","WITH CTE_Hist_Equipe AS (\n","    SELECT DISTINCT\n","        HSE.CODCOLIGADA,\n","        HSE.CHAPA,\n","        HSE.CODEQUIPE AS EQUIPE,\n","        PE.DESCRICAO AS DESCRICAO_EQUIPE,\n","        HSE.DTMUDANCA,\n","        ISNULL(\n","            LEAD(HSE.DTMUDANCA, 1) OVER (\n","                PARTITION BY HSE.CODCOLIGADA, HSE.CHAPA\n","                ORDER BY HSE.DTMUDANCA\n","            ),\n","            CAST(GETDATE() AS DATE)\n","        ) AS PROXIMA_DATAMUDANCA_EQP\n","    FROM zmd_hst_equipe AS HSE\n","    LEFT JOIN pequipe AS PE\n","        ON HSE.CODEQUIPE = PE.CODCLIENTE\n",")\n","SELECT\n","    PFUNC.CODCOLIGADA                                   AS COLIGADA,\n","    PFUNC.NOME                                          AS NOME,\n","    PFUNC.CHAPA                                         AS CHAPA,\n","    EQP.EQUIPE,\n","    EQP.DESCRICAO_EQUIPE,\n","    PSECAO.CODIGO                                       AS CODIGO_SECAO,\n","    --PSECAO.DESCRICAO                                  AS SECAO,\n","    PFUNC.CODFUNCAO                                     AS CODIGO_FUNCAO,\n","    PFUNCAO.NOME                                        AS DESCRICAO_FUNCAO,\n","    ABATFUN.DATA                                        AS DATA,\n","    YEAR(ABATFUN.DATA)                                  AS ANO,\n","    MONTH(ABATFUN.DATA)                                 AS MES,\n","    DAY(ABATFUN.DATA)                                   AS DIA,\n","    DATAREFERENCIA                                      AS DATA_REFERENCIA,\n","    ABATFUN.BATIDA                                      AS RM_BATIDA,\n","    SUBSTRING(PFUNC.CODSECAO, 11, 4)                    AS OBRA,\n","    RIGHT('00' + CAST((ABATFUN.BATIDA / 60) AS varchar(2)), 2)\n","        + ':' +\n","    RIGHT('00' + CAST((ABATFUN.BATIDA - (ABATFUN.BATIDA / 60 * 60)) AS varchar(2)), 2)\n","                                                        AS BATIDA,\n","    ABATFUN.STATUS                                      AS STATUS_BATIDA,\n","    ABATFUN.NATUREZA                                    AS NATUREZA,\n","    AAFDT.JUSTIFICATIVA                                 AS JUSTIFICATIVA,\n","    AHORARIO.DESCRICAO                                  AS GRADE_HORARIO\n","FROM ABATFUN\n","INNER JOIN AAFDT\n","    ON AAFDT.CODCOLIGADA = ABATFUN.CODCOLIGADA\n","   AND AAFDT.ID = ABATFUN.IDAAFDT\n","INNER JOIN PFUNC\n","    ON ABATFUN.CHAPA = PFUNC.CHAPA\n","INNER JOIN AHORARIO\n","    ON PFUNC.CODCOLIGADA = AHORARIO.CODCOLIGADA\n","   AND PFUNC.CODHORARIO = AHORARIO.CODIGO\n","INNER JOIN PFUNCAO\n","    ON PFUNC.CODCOLIGADA = PFUNCAO.CODCOLIGADA\n","   AND PFUNC.CODFUNCAO = PFUNCAO.CODIGO    \n","INNER JOIN PSECAO\n","    ON PFUNC.CODCOLIGADA = PSECAO.CODCOLIGADA\n","   AND PFUNC.CODSECAO = PSECAO.CODIGO\n","LEFT JOIN CTE_Hist_Equipe AS EQP\n","    ON PFUNC.CODCOLIGADA = EQP.CODCOLIGADA\n","   AND PFUNC.CHAPA = EQP.CHAPA\n","   AND CAST(ABATFUN.DATA AS DATE) >= CAST(EQP.DTMUDANCA AS DATE)\n","   AND CAST(ABATFUN.DATA AS DATE) <  CAST(EQP.PROXIMA_DATAMUDANCA_EQP AS DATE)\n","WHERE ABATFUN.DATA >= DATEADD(DAY, -35, CAST(GETDATE() AS DATE))\n","\"\"\"\n","\n","\n","# ============================================\n","# 3) Ler do SQL Server (via JDBC) para Spark\n","# ============================================\n","df_ponto = (\n","    spark.read\n","    .format(\"jdbc\")\n","    .option(\"url\", jdbc_url)\n","    .option(\"user\", jdbc_username)\n","    .option(\"password\", jdbc_password)\n","    .option(\"driver\", \"com.microsoft.sqlserver.jdbc.SQLServerDriver\")\n","    .option(\"query\", consulta)\n","    .load()\n",")\n","\n","# Opcional: inspecionar esquema e algumas linhas\n","df_ponto.printSchema()\n","display(df_ponto.limit(20))\n","\n","\n","# Salva no Lakehouse de destino usando caminho físico\n","df_resultado.write.format(\"delta\").mode(\"overwrite\").save(path_destino)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"9922e368-d36a-450c-98d7-1972c49f96cd","normalized_state":"finished","queued_time":"2025-11-18T18:48:17.7588442Z","session_start_time":null,"execution_start_time":"2025-11-18T18:48:17.7602984Z","execution_finish_time":"2025-11-18T18:48:48.4566747Z","parent_msg_id":"d668700b-f475-45ff-8442-47edf2c456ac"},"text/plain":"StatementMeta(, 9922e368-d36a-450c-98d7-1972c49f96cd, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["JDBC URL: jdbc:sqlserver://142.0.64.50:38000;database=C8VSAQ_144754_RM_PD;encrypt=false;trustServerCertificate=true;\n"]},{"output_type":"error","ename":"Py4JJavaError","evalue":"An error occurred while calling o4659.load.\n: com.microsoft.sqlserver.jdbc.SQLServerException: The TCP/IP connection to the host 142.0.64.50, port 38000 has failed. Error: \"connect timed out. Verify the connection properties. Make sure that an instance of SQL Server is running on the host and accepting TCP/IP connections at the port. Make sure that TCP connections to the port are not blocked by a firewall.\".\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDriverError(SQLServerException.java:231)\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.convertConnectExceptionToSQLServerException(SQLServerException.java:282)\n\tat com.microsoft.sqlserver.jdbc.SocketFinder.findSocket(IOBuffer.java:2578)\n\tat com.microsoft.sqlserver.jdbc.TDSChannel.open(IOBuffer.java:719)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectHelper(SQLServerConnection.java:3523)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.login(SQLServerConnection.java:3172)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectInternal(SQLServerConnection.java:3014)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connect(SQLServerConnection.java:1836)\n\tat com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(SQLServerDriver.java:1246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:123)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:119)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:236)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:219)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:219)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 107\u001b[0m\n\u001b[1;32m     28\u001b[0m consulta \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124mWITH CTE_Hist_Equipe AS (\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m    SELECT DISTINCT\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124mWHERE ABATFUN.DATA >= DATEADD(DAY, -35, CAST(GETDATE() AS DATE))\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# 3) Ler do SQL Server (via JDBC) para Spark\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# ============================================\u001b[39;00m\n\u001b[1;32m     99\u001b[0m df_ponto \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    100\u001b[0m     \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjdbc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjdbc_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjdbc_username\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjdbc_password\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcom.microsoft.sqlserver.jdbc.SQLServerDriver\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsulta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 107\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m )\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Opcional: inspecionar esquema e algumas linhas\u001b[39;00m\n\u001b[1;32m    111\u001b[0m df_ponto\u001b[38;5;241m.\u001b[39mprintSchema()\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/sql/readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n","File \u001b[0;32m/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n","File \u001b[0;32m~/cluster-env/trident_env/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n","\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4659.load.\n: com.microsoft.sqlserver.jdbc.SQLServerException: The TCP/IP connection to the host 142.0.64.50, port 38000 has failed. Error: \"connect timed out. Verify the connection properties. Make sure that an instance of SQL Server is running on the host and accepting TCP/IP connections at the port. Make sure that TCP connections to the port are not blocked by a firewall.\".\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.makeFromDriverError(SQLServerException.java:231)\n\tat com.microsoft.sqlserver.jdbc.SQLServerException.convertConnectExceptionToSQLServerException(SQLServerException.java:282)\n\tat com.microsoft.sqlserver.jdbc.SocketFinder.findSocket(IOBuffer.java:2578)\n\tat com.microsoft.sqlserver.jdbc.TDSChannel.open(IOBuffer.java:719)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectHelper(SQLServerConnection.java:3523)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.login(SQLServerConnection.java:3172)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connectInternal(SQLServerConnection.java:3014)\n\tat com.microsoft.sqlserver.jdbc.SQLServerConnection.connect(SQLServerConnection.java:1836)\n\tat com.microsoft.sqlserver.jdbc.SQLServerDriver.connect(SQLServerDriver.java:1246)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.BasicConnectionProvider.getConnection(BasicConnectionProvider.scala:49)\n\tat org.apache.spark.sql.execution.datasources.jdbc.connection.ConnectionProviderBase.create(ConnectionProvider.scala:102)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1(JdbcDialects.scala:123)\n\tat org.apache.spark.sql.jdbc.JdbcDialect.$anonfun$createConnectionFactory$1$adapted(JdbcDialects.scala:119)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.getQueryOutputSchema(JDBCRDD.scala:63)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD$.resolveTable(JDBCRDD.scala:58)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRelation$.getSchema(JDBCRelation.scala:241)\n\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:37)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:346)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:236)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:219)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:219)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:174)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"e23c6776-73a6-47f4-b58d-ff72b18be3f8\",\"activityId\":\"9922e368-d36a-450c-98d7-1972c49f96cd\",\"applicationId\":\"application_1763490760102_0001\",\"jobGroupId\":\"4\",\"advices\":{\"error\":1}}"},"cellStatus":"{\"Suporte BI\":{\"session_start_time\":null,\"execution_start_time\":\"2025-11-18T18:48:17.7602984Z\",\"execution_finish_time\":\"2025-11-18T18:48:48.4566747Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}"},"id":"869bcac8-c7bc-4c2b-8141-4b7ccda95d24"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}