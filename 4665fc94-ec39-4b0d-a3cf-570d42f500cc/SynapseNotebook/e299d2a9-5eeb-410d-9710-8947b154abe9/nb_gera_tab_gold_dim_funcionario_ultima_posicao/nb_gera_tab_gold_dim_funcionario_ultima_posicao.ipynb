{"cells":[{"cell_type":"code","source":["from pyspark.sql.functions import col\n","\n","# ============================================================\n","# 0. Configurações de Otimização do Fabric\n","# ============================================================\n","# Habilita o V-Order (padrão no Fabric, mas garante escrita otimizada)\n","spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\") # ~1GB por arquivo se possível\n","\n","# ============================================================\n","# 1. Caminho físico\n","# ============================================================\n","path_destino = (\n","    \"abfss://ws_departamento_pessoal@onelake.dfs.fabric.microsoft.com/\"\n","    \"lk_departamento_pessoal.Lakehouse/Tables/tab_gold_dim_funcionario_ultima_posicao_mes\"\n",")\n","\n","# ============================================================\n","# 2. Ler e Filtrar\n","# ============================================================\n","df_historico = spark.table(\"tab_gold_dim_funcionario_historico\")\n","\n","df_filtrado = df_historico.filter(col(\"RK_MES\") == 1)\n","\n","# ============================================================\n","# 3. CORREÇÃO DO SKEW\n","#\n","#    Removido col(\"CODCOLIGADA\"), col(\"SECAO\").\n","#    Usando apenas o número, o Spark faz um Round-Robin,\n","#    distribuindo os dados igualmente independente do conteúdo.\n","# ============================================================\n","NUM_PARTICOES = 200  # Se tiver menos de 10GB de dados, pode até baixar para 20-50\n","\n","df_reparticionado = df_filtrado.repartition(NUM_PARTICOES)\n","\n","# ============================================================\n","# 4. Escrever\n","# ============================================================\n","(\n","    df_reparticionado.write\n","        .format(\"delta\")\n","        .mode(\"overwrite\")\n","        .option(\"overwriteSchema\", \"true\") # Boa prática se a estrutura mudar\n","        .save(path_destino)\n",")\n","\n","print(f\"Gravação concluída. Partições utilizadas: {NUM_PARTICOES}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"cb0f5827-d535-4e18-817c-d3c05d6156cc","normalized_state":"finished","queued_time":"2025-09-18T12:22:07.693689Z","session_start_time":"2025-09-18T12:22:07.6945433Z","execution_start_time":"2025-09-18T12:22:19.8465462Z","execution_finish_time":"2025-09-18T12:22:42.960878Z","parent_msg_id":"70926f15-e99f-44ec-aa5b-298f3d90ee6b"},"text/plain":"StatementMeta(, cb0f5827-d535-4e18-817c-d3c05d6156cc, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"cellStatus":"{\"Suporte BI\":{\"session_start_time\":\"2025-09-18T12:22:07.6945433Z\",\"execution_start_time\":\"2025-09-18T12:22:19.8465462Z\",\"execution_finish_time\":\"2025-09-18T12:22:42.960878Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}"},"id":"f625b998-4365-4ea7-89b6-2927afc92ca4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"2df79f82-2938-4b29-9d25-58c6ffa4aba7"}],"default_lakehouse":"2df79f82-2938-4b29-9d25-58c6ffa4aba7","default_lakehouse_name":"lk_departamento_pessoal","default_lakehouse_workspace_id":"4665fc94-ec39-4b0d-a3cf-570d42f500cc"}}},"nbformat":4,"nbformat_minor":5}