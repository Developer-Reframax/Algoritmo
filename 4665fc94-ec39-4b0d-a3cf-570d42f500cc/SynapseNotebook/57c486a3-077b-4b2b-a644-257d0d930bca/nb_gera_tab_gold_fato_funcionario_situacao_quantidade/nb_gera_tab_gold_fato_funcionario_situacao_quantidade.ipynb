{"cells":[{"cell_type":"code","source":["# ============================================================\n","# Notebook único: cálculo + escrita Delta (sem mudar particionamento)\n","# - Se a tabela não existir: cria sem partição (compatível com seu estado atual)\n","# - Se já existir: faz MERGE (upsert) pelos campos-chave (DATA, SITUACAO, DESCRICAO_SITUACAO)\n","# ============================================================\n","from pyspark.sql import functions as F\n","from pyspark.sql.utils import AnalysisException\n","from delta.tables import DeltaTable\n","import time\n","\n","# -----------------------------\n","# CONFIGURAÇÕES\n","# -----------------------------\n","path_destino = \"abfss://ws_departamento_pessoal@onelake.dfs.fabric.microsoft.com/lk_departamento_pessoal.Lakehouse/Tables/tab_gold_fato_funcionario_situacao_quantidade\"\n","\n","# (Opcional) Nome lógico no catálogo; deixe None para pular\n","catalog_table_name = None  # Ex.: \"lk_departamento_pessoal.tab_gold_fato_funcionario_situacao_quantidade\"\n","\n","MAX_RETRIES = 3\n","BASE_SLEEP  = 5  # segundos (backoff linear)\n","\n","# -----------------------------\n","# CONSULTA (sua lógica do último dia do mês)\n","# -----------------------------\n","sql_query = \"\"\"\n","WITH UltimoDiaMes AS (\n","    SELECT \n","        CAST(DATE_TRUNC('MONTH', DATA) AS DATE) AS PrimeiroDiaMes,\n","        MAX(DATA) AS UltimaDataMes\n","    FROM tab_gold_dim_funcionario_historico\n","    GROUP BY DATE_TRUNC('MONTH', DATA)\n",")\n","SELECT \n","    U.UltimaDataMes AS DATA,\n","    FH.SITUACAO,\n","    FH.DESCRICAO_SITUACAO,\n","    COUNT(*) AS QUANTIDADE_FUNCIONARIO\n","FROM UltimoDiaMes U\n","JOIN tab_gold_dim_funcionario_historico FH\n","    ON FH.DATA = U.UltimaDataMes\n","GROUP BY \n","    U.UltimaDataMes,\n","    FH.SITUACAO,\n","    FH.DESCRICAO_SITUACAO\n","\"\"\"\n","df_resultado = spark.sql(sql_query)\n","df_resultado.cache()\n","print(\"Prévia do resultado:\")\n","df_resultado.show(20, truncate=False)\n","\n","# -----------------------------\n","# HELPERS\n","# -----------------------------\n","def delta_table_exists(path: str) -> bool:\n","    try:\n","        DeltaTable.forPath(spark, path)\n","        return True\n","    except Exception:\n","        return False\n","\n","def is_concurrent_exc(e: Exception) -> bool:\n","    s = str(e)\n","    return (\"ConcurrentAppendException\" in s\n","            or \"checkForConflicts\" in s\n","            or \"conflicts\" in s)\n","\n","# -----------------------------\n","# ESCRITA\n","#   - Se não existe: cria tabela sem partição (overwrite inicial)\n","#   - Se existe: MERGE (upsert) por DATA+SITUACAO+DESCRICAO_SITUACAO\n","# -----------------------------\n","if not delta_table_exists(path_destino):\n","    # Criação inicial, mantendo sem particionamento (compatível com o estado reportado)\n","    print(\"[INFO] Tabela não existe. Criando (overwrite inicial, sem partição).\")\n","    (df_resultado\n","        .write\n","        .format(\"delta\")\n","        .mode(\"overwrite\")\n","        .save(path_destino))\n","\n","    if catalog_table_name:\n","        spark.sql(f\"CREATE TABLE IF NOT EXISTS {catalog_table_name} USING DELTA LOCATION '{path_destino}'\")\n","        print(f\"[OK] Tabela registrada no catálogo: {catalog_table_name}\")\n","\n","else:\n","    print(\"[INFO] Tabela existe. Executando MERGE (upsert) para evitar overwrite total e manter o particionamento atual.\")\n","    # Cria uma view temporária do source para usar no MERGE SQL ou usa API Python.\n","    # Aqui vamos pela API Python do DeltaTable.\n","    dt = DeltaTable.forPath(spark, path_destino)\n","\n","    # Para garantir idempotência e lidar com concorrência leve, aplicamos retentativa.\n","    last_err = None\n","    for attempt in range(1, MAX_RETRIES + 1):\n","        try:\n","            (dt.alias(\"t\")\n","               .merge(\n","                   df_resultado.alias(\"s\"),\n","                   \"t.DATA = s.DATA \"\n","                   \"AND t.SITUACAO = s.SITUACAO \"\n","                   \"AND t.DESCRICAO_SITUACAO = s.DESCRICAO_SITUACAO\"\n","               )\n","               .whenMatchedUpdate(set={\n","                   \"QUANTIDADE_FUNCIONARIO\": \"s.QUANTIDADE_FUNCIONARIO\"\n","               })\n","               .whenNotMatchedInsertAll()\n","               .execute())\n","            print(f\"[OK] MERGE concluído (tentativa {attempt}).\")\n","            last_err = None\n","            break\n","        except Exception as e:\n","            last_err = e\n","            if is_concurrent_exc(e) and attempt < MAX_RETRIES:\n","                wait_s = BASE_SLEEP * attempt\n","                print(f\"[Aviso] Concorrência detectada no MERGE (tentativa {attempt}). Aguardando {wait_s}s para retentar...\")\n","                time.sleep(wait_s)\n","            else:\n","                print(f\"[Erro] MERGE falhou na tentativa {attempt}.\")\n","                raise\n","\n","    if last_err is None and catalog_table_name:\n","        spark.sql(f\"CREATE TABLE IF NOT EXISTS {catalog_table_name} USING DELTA LOCATION '{path_destino}'\")\n","        print(f\"[OK] Tabela confirmada/registrada no catálogo: {catalog_table_name}\")\n","\n","# -----------------------------\n","# (Opcional) Ver histórico após a escrita\n","# -----------------------------\n","try:\n","    dt_final = DeltaTable.forPath(spark, path_destino)\n","    print(\"Histórico Delta (últimos 10 commits):\")\n","    dt_final.history().show(10, truncate=False)\n","except Exception as e:\n","    print(\"Não foi possível ler o histórico após a escrita.\")\n","    print(e)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"3a5a0a5d-a0a8-4324-a939-f7cff0cd248e","normalized_state":"finished","queued_time":"2025-09-23T11:20:05.6830497Z","session_start_time":"2025-09-23T11:20:05.6841335Z","execution_start_time":"2025-09-23T11:20:17.7033132Z","execution_finish_time":"2025-09-23T11:21:00.6142032Z","parent_msg_id":"f111c9c3-075b-44b5-9acc-05050c5859d9"},"text/plain":"StatementMeta(, 3a5a0a5d-a0a8-4324-a939-f7cff0cd248e, 3, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Prévia do resultado:\n+----------+--------+---------------------------------+----------------------+\n|DATA      |SITUACAO|DESCRICAO_SITUACAO               |QUANTIDADE_FUNCIONARIO|\n+----------+--------+---------------------------------+----------------------+\n|2025-06-30|E       |Licença Mater.                   |4                     |\n|2025-01-31|V       |Aviso Prévio                     |75                    |\n|2020-02-29|F       |Férias                           |108                   |\n|2008-08-31|P       |Af.Previdência                   |15                    |\n|2008-10-31|P       |Af.Previdência                   |16                    |\n|2005-07-31|P       |Af.Previdência                   |7                     |\n|2024-04-30|E       |Licença Mater.                   |5                     |\n|2023-06-30|E       |Licença Mater.                   |4                     |\n|2010-06-30|T       |Af.Ac.Trabalho                   |1                     |\n|2010-08-31|T       |Af.Ac.Trabalho                   |1                     |\n|2004-01-31|P       |Af.Previdência                   |6                     |\n|2009-04-30|D       |Demitido                         |52                    |\n|2006-05-31|T       |Af.Ac.Trabalho                   |1                     |\n|2003-07-31|A       |Ativo                            |263                   |\n|2025-02-28|V       |Aviso Prévio                     |74                    |\n|2021-01-31|I       |Apos. por Incapacidade Permanente|51                    |\n|2023-12-31|P       |Af.Previdência                   |131                   |\n|2008-09-30|P       |Af.Previdência                   |16                    |\n|2004-09-30|P       |Af.Previdência                   |5                     |\n|2007-02-28|P       |Af.Previdência                   |13                    |\n+----------+--------+---------------------------------+----------------------+\nonly showing top 20 rows\n\n[INFO] Tabela existe. Executando MERGE (upsert) para evitar overwrite total e manter o particionamento atual.\n[OK] MERGE concluído (tentativa 1).\nHistórico Delta (últimos 10 commits):\n+-------+-----------------------+------+--------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------+\n|version|timestamp              |userId|userName|operation|operationParameters                                                                                                                                                                                                                                                           |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |userMetadata|engineInfo                                           |\n+-------+-----------------------+------+--------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------+\n|2      |2025-09-23 11:20:58.258|null  |null    |MERGE    |{predicate -> [\"(((DATA#1327 = DATA#590) AND (SITUACAO#1328 = SITUACAO#677)) AND (DESCRICAO_SITUACAO#1329 = DESCRICAO_SITUACAO#678))\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|null|null    |null     |1          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 10965, numTargetBytesRemoved -> 10965, numTargetRowsMatchedUpdated -> 1976, executionTimeMs -> 11545, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, unmodifiedRewriteTimeMs -> 763, scanTimeMs -> 5416, numTargetRowsUpdated -> 1976, numOutputRows -> 1976, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 1976, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 3754}|null        |Apache-Spark/3.4.3.5.3.20250628.1 Delta-Lake/2.4.0.25|\n|1      |2025-09-23 11:00:43.764|null  |null    |MERGE    |{predicate -> [\"(((DATA#1327 = DATA#590) AND (SITUACAO#1328 = SITUACAO#677)) AND (DESCRICAO_SITUACAO#1329 = DESCRICAO_SITUACAO#678))\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}|null|null    |null     |0          |Serializable  |false        |{numTargetRowsCopied -> 9, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 2, numTargetBytesAdded -> 13476, numTargetBytesRemoved -> 10592, numTargetRowsMatchedUpdated -> 1967, executionTimeMs -> 11288, numTargetRowsInserted -> 9, numTargetRowsMatchedDeleted -> 0, unmodifiedRewriteTimeMs -> 776, scanTimeMs -> 5661, numTargetRowsUpdated -> 1967, numOutputRows -> 1985, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 1976, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 3516}|null        |Apache-Spark/3.4.3.5.3.20250628.1 Delta-Lake/2.4.0.25|\n|0      |2025-09-22 19:25:08.451|null  |null    |WRITE    |{mode -> Overwrite, partitionBy -> []}                                                                                                                                                                                                                                        |null|null    |null     |null       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 1976, numOutputBytes -> 10592}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |null        |Apache-Spark/3.4.3.5.3.20250603.1 Delta-Lake/2.4.0.25|\n+-------+-----------------------+------+--------+---------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------------------------+\n\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"cellStatus":"{\"Suporte BI\":{\"session_start_time\":\"2025-09-23T11:20:05.6841335Z\",\"execution_start_time\":\"2025-09-23T11:20:17.7033132Z\",\"execution_finish_time\":\"2025-09-23T11:21:00.6142032Z\",\"state\":\"finished\",\"livy_statement_state\":\"available\",\"normalized_state\":\"finished\"}}","advisor":{"adviceMetadata":"{\"artifactId\":\"57c486a3-077b-4b2b-a644-257d0d930bca\",\"activityId\":\"3a5a0a5d-a0a8-4324-a939-f7cff0cd248e\",\"applicationId\":\"application_1758625800969_0001\",\"jobGroupId\":\"3\",\"advices\":{\"warn\":1}}"}},"id":"f625b998-4365-4ea7-89b6-2927afc92ca4"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"2df79f82-2938-4b29-9d25-58c6ffa4aba7"}],"default_lakehouse":"2df79f82-2938-4b29-9d25-58c6ffa4aba7","default_lakehouse_name":"lk_departamento_pessoal","default_lakehouse_workspace_id":"4665fc94-ec39-4b0d-a3cf-570d42f500cc"}}},"nbformat":4,"nbformat_minor":5}